{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cd043b6-c448-419a-95af-2e09d95f80bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wic053/miniforge3/envs/py312/lib/python3.12/site-packages/pydantic/_migration.py:283: UserWarning: `pydantic.error_wrappers:ValidationError` has been moved to `pydantic:ValidationError`.\n",
      "  warnings.warn(f'`{import_path}` has been moved to `{new_location}`.')\n"
     ]
    }
   ],
   "source": [
    "# system\n",
    "import os\n",
    "import csv\n",
    "from typing import Dict\n",
    "\n",
    "# langchain\n",
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "\n",
    "# Vector DB\n",
    "from docarray.index import InMemoryExactNNIndex\n",
    "\n",
    "# code utils\n",
    "import black\n",
    "\n",
    "# utils\n",
    "from utils.models import VecDBEntry\n",
    "from utils.db import search_db\n",
    "from utils.templates import get_extractor_chain, get_data_extractor_map_chain\n",
    "from utils.models import Scope, ScopeEnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f27aa781-6f81-4a05-9967-faa40a9c65e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = os.environ[\"OPENAI_API_KEY\"]\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = os.environ[\"OPENAI_API_BASE\"]\n",
    "os.environ[\"AZURE_OPENAI_API_VERSION\"] = os.environ[\"OPENAI_API_VERSION\"]\n",
    "os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"] = \"firstcontact-gpt4-turbo\"\n",
    "\n",
    "del os.environ[\"OPENAI_API_BASE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a07dff28-1039-49b0-ae1a-f7816b880a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_json = AzureChatOpenAI(\n",
    "    openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "    azure_deployment=os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"],\n",
    "    model=\"gpt-4-128k\",\n",
    "    model_kwargs={\"response_format\": {\"type\": \"json_object\"}},\n",
    ")\n",
    "\n",
    "embeddings_model = AzureOpenAIEmbeddings(\n",
    "    azure_deployment=\"firstcontact-embeddings\", model=\"gpt-4-128k\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1d86fa-2c42-41ef-acbd-144a24f89245",
   "metadata": {},
   "source": [
    "## Extract data and generate SDK construct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44195e0c-acdf-4f93-aaa8-5ea4536a3894",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "\n",
    "with open(\"./embeddings.csv\") as fp:\n",
    "    reader = csv.reader(fp)\n",
    "    for row, (term, label, scope, embedding) in enumerate(reader):\n",
    "        if row == 0:\n",
    "            continue\n",
    "        embedding = eval(embedding)\n",
    "        docs.append(\n",
    "            VecDBEntry(term=term, label=label, scope=scope, embedding=embedding)\n",
    "        )\n",
    "db = InMemoryExactNNIndex[VecDBEntry]()\n",
    "db.index(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85ec7fb7-4ec3-4269-84a3-9a732e1a781d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_extractor_code(query: str) -> Dict:\n",
    "    extractor_chain = get_data_extractor_map_chain(llm_json)\n",
    "    extracted_data = extractor_chain.invoke(query)\n",
    "\n",
    "    print(f\"{extracted_data=}\")\n",
    "    print(f\"filters text: {extracted_data[\"filters\"].filters}\")\n",
    "\n",
    "    if len(extracted_data[\"filters\"].filters) > 0:\n",
    "        filters = extracted_data[\"filters\"]\n",
    "        filters = filters.model_dump(mode=\"json\")[\"filters\"]\n",
    "        hits = []\n",
    "\n",
    "        for fil in filters:\n",
    "            entries, scores = search_db(db, fil[\"term\"], embeddings_model)\n",
    "            for entry, score in zip(entries, scores):\n",
    "                if score < 0.9:\n",
    "                    break\n",
    "                hits.append(\n",
    "                    {\n",
    "                        \"scope\": fil[\"scope\"],\n",
    "                        \"term\": entry.term,\n",
    "                        \"score\": score,\n",
    "                        \"label\": entry.label,\n",
    "                        \"query\": fil[\"term\"],\n",
    "                    }\n",
    "                )\n",
    "        extracted_data[\"filters\"] = hits\n",
    "        print(f\"filters coded: {hits}\")\n",
    "    else:\n",
    "        extracted_data[\"filters\"] = []\n",
    "\n",
    "    sdk_construct = \"data = BeaconV2()\"\n",
    "    sdk_comments = \"\"\n",
    "\n",
    "    scope = extracted_data.get(\"scope\", Scope(scope=ScopeEnum.UNKNOWN))\n",
    "    filters = extracted_data[\"filters\"]\n",
    "\n",
    "    if extracted_data[\"variant\"].success:\n",
    "        sdk_comments += f\"\"\"# Variants detected in the query.\\n\"\"\"\n",
    "        sdk_construct += f\"\"\".with_g_variant(\"\"\"\n",
    "        print(f\"variant found: {extracted_data[\"variant\"].dict()}\")\n",
    "        assembly_id = extracted_data[\"variant\"].assembly_id\n",
    "        sdk_construct += \"'GRCH38'\" if assembly_id == \"unknown\" else f\"'{assembly_id}'\"\n",
    "        sdk_construct += \",'N','N',\"\n",
    "        start = extracted_data[\"variant\"].start\n",
    "        if isinstance(start, list):\n",
    "            sdk_construct += \"[0],\" if start == \"unknown\" else f\"{start},\"\n",
    "        else:\n",
    "            sdk_construct += \"[0],\" if start == \"unknown\" else f\"[{start}],\"\n",
    "        end = extracted_data[\"variant\"].end\n",
    "        if isinstance(end, list):\n",
    "            sdk_construct += \"[0],\" if end == \"unknown\" else f\"{end},\"\n",
    "        else:\n",
    "            sdk_construct += \"[0],\" if end == \"unknown\" else f\"[{end}],\"\n",
    "        reference_name = extracted_data[\"variant\"].chromosome\n",
    "        sdk_construct += \"'1'\" if reference_name == \"unknown\" else f\"'{reference_name}'\"\n",
    "        sdk_construct += \")\"\n",
    "\n",
    "    if scope.scope != ScopeEnum.UNKNOWN:\n",
    "        print(f\"{scope=}\")\n",
    "        scope = scope.model_dump(mode=\"json\")[\"scope\"]\n",
    "        sdk_construct += f\"\"\".with_scope(\"{scope}\")\"\"\"\n",
    "        sdk_comments += f\"\"\"# Scope detected to be '{scope}'.\\n\"\"\"\n",
    "    else:\n",
    "        sdk_comments += f\"\"\"# Could not decide a scope for your query.\\n\"\"\"\n",
    "        sdk_construct += f\"\"\".with_scope('<ENTER YOUR SCOPE>')\"\"\"\n",
    "\n",
    "    for fil in filters:\n",
    "        print(f\"{fil=}\")\n",
    "        sdk_comments += f\"\"\"# {fil[\"term\"]} -> '{fil[\"label\"]}'\\n\"\"\"\n",
    "        sdk_construct += (\n",
    "            f\"\"\".with_filter('ontology', '{fil[\"term\"]}', '{fil[\"scope\"]}') \"\"\"\n",
    "        )\n",
    "\n",
    "    sdk_construct = (\n",
    "        sdk_construct\n",
    "        + \".load()\"\n",
    "        + \"\\n\\n\"\n",
    "        + sdk_comments\n",
    "        + \"\\n# Please update this line with other dataframes\"\n",
    "        + \"\\ndataframes = [data]\"\n",
    "    )\n",
    "\n",
    "    sdk_construct = black.format_str(sdk_construct, mode=black.FileMode())\n",
    "\n",
    "    return sdk_construct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b61a7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracted_data={'scope': Scope(scope=<ScopeEnum.INDIVIDUALS: 'individuals'>), 'filters': Filters(filters=[Filter(term=\"Parkinson's\", scope=<ScopeEnum.INDIVIDUALS: 'individuals'>)]), 'variant': Variant(success=True, assembly_id='unknown', chromosome='1', start=[10000], end=[15000]), 'granularity': Granularity(granularity=<GranularityEnum.RECORD: 'record'>), 'query': \"Individuals with Parkinson's with variants in first chromosome from the 10000-15000 bases\"}\n",
      "filters text: [Filter(term=\"Parkinson's\", scope=<ScopeEnum.INDIVIDUALS: 'individuals'>)]\n",
      "filters coded: [{'scope': 'individuals', 'term': 'SNOMED:49049000', 'score': np.float64(0.9633136720184313), 'label': \"Parkinson's disease\", 'query': \"Parkinson's\"}]\n",
      "variant found: {'success': True, 'assembly_id': 'unknown', 'chromosome': '1', 'start': [10000], 'end': [15000]}\n",
      "scope=Scope(scope=<ScopeEnum.INDIVIDUALS: 'individuals'>)\n",
      "fil={'scope': 'individuals', 'term': 'SNOMED:49049000', 'score': np.float64(0.9633136720184313), 'label': \"Parkinson's disease\", 'query': \"Parkinson's\"}\n"
     ]
    }
   ],
   "source": [
    "sdk_construct = generate_extractor_code(\n",
    "    \"Individuals with Parkinson's with variants in first chromosome from the 10000-15000 bases\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b33b7e3-703b-4f6a-9481-2112dda95eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data = (\n",
      "    BeaconV2()\n",
      "    .with_g_variant(\"GRCH38\", \"N\", \"N\", [10000], [15000], \"1\")\n",
      "    .with_scope(\"individuals\")\n",
      "    .with_filter(\"ontology\", \"SNOMED:49049000\", \"individuals\")\n",
      "    .load()\n",
      ")\n",
      "\n",
      "# Variants detected in the query.\n",
      "# Scope detected to be 'individuals'.\n",
      "# SNOMED:49049000 -> 'Parkinson's disease'\n",
      "\n",
      "# Please update this line with other dataframes\n",
      "dataframes = [data]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sdk_construct)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
